{"cells":[{"metadata":{},"cell_type":"markdown","source":"## **0. Introduction and References**\nI decided to write this kernel when I first started learning about NLP. It is basically the things I learned documented in Kaggle Notebook format. It can be helpful for you if you are looking for **data analysis on competition data**, **feature engineering ideas for NLP**, **cleaning and text processing ideas**, **baseline BERT model** or **test set with labels**. If you have any idea that might improve this kernel, please be sure to comment, or fork and experiment as you like. If you don't understand any part, feel free to ask in the comment section.\n\nThis kernel includes codes and ideas from kernels below. If this kernel helps you, please upvote their work as well. \n* [Simple Exploration Notebook - QIQC](https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-qiqc) by [@sudalairajkumar](https://www.kaggle.com/sudalairajkumar)\n* [How to: Preprocessing when using embeddings](https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings) by [@christofhenkel](https://www.kaggle.com/christofhenkel)\n* [Improve your Score with some Text Preprocessing](https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing) by [@theoviel](https://www.kaggle.com/theoviel)\n* [A Real Disaster - Leaked Label](https://www.kaggle.com/szelee/a-real-disaster-leaked-label) by [@szelee](https://www.kaggle.com/szelee)\n* [Disaster NLP: Keras BERT using TFHub](https://www.kaggle.com/xhlulu/disaster-nlp-keras-bert-using-tfhub) by [@xhlulu](https://www.kaggle.com/xhlulu)"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py","execution_count":1,"outputs":[{"output_type":"stream","text":"wget: /opt/conda/lib/libuuid.so.1: no version information available (required by wget)\r\n","name":"stdout"}]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import gc\nimport re\nimport string\nimport operator\nfrom collections import defaultdict\n\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tokenization\nfrom wordcloud import STOPWORDS\n\nfrom sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow import keras\nfrom tensorflow.keras.optimizers import SGD, Adam\nfrom tensorflow.keras.layers import Dense, Input, Dropout, GlobalAveragePooling1D\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n\nSEED = 1337","execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\n\nfor df in [df_train, df_test]:\n    for col in ['keyword', 'location']:\n        df[col] = df[col].fillna(f'no_{col}')","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **4. Embeddings and Text Cleaning**"},{"metadata":{},"cell_type":"markdown","source":"### **4.2 Text Cleaning**\nTweets require lots of cleaning but it is inefficient to clean every single tweet because that would consume too much time. A general approach must be implemented for cleaning.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport os\n#import spacy\n#nlp_vects = spacy.load('en_vectors_web_lg')\nfrom spellchecker import SpellChecker\n\ndef manage_contractions(tweet):\n    tweet = tweet.text\n    tweet_ = tweet\n\n    # Contractions\n    tweet = re.sub(r\"\\bain'?t\\b\", \"am not\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\baren'?t\\b\", \"are not\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bcan'?t\\b\", \"cannot\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bcouldn'?t\\b\", \"could not\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bcould'?ve\\b\", \"could have\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bdidn'?t\\b\", \"did not\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bdoesn'?t\\b\", \"does not\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bdon'?t\\b\", \"do not\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bhasn'?t\\b\", \"has not\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bhaven'?t\\b\", \"have not\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bhe'?ll\\b\", \"he will\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bhere'?s\\b\", \"here is\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bhe'?s\\b\", \"he is\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bi'?d\\b\", \"i would\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bi'?ll\\b\", \"i will\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bi'?m\\b\", \"i am\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bisn'?t\\b\", \"is not\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bit'?ll\\b\", \"it will\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bit'?s\\b\", \"it is\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bit'?s\\b\", \"it is\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bi'?ve\\b\", \"i have\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\blet'?s\\b\", \"let us\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bshouldn'?t\\b\", \"should not\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bshould'?ve\\b\", \"should have\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bthat'?s\\b\", \"that is\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bthere'?s\\b\", \"there is\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bthey'?d\\b\", \"they would\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bthey'?ll\\b\", \"they will\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bthey'?re\\b\", \"they are\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bthey'?ve\\b\", \"they have\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bwasn'?t\\b\", \"was not\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bwe'?d\\b\", \"we would\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bwe'?ll\\b\", \"we will\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bwe'?re\\b\", \"we are\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bweren'?t\\b\", \"were not\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bwe'?ve\\b\", \"we have\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bwhat'?s\\b\", \"what is\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bwhere'?s\\b\", \"where is\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bwho'?s\\b\", \"who is\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bwon'?t\\b\", \"will not\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bwouldn'?t\\b\", \"would not\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\bwould'?ve\\b\", \"would have\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\by'?all\\b\", \"you all\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\byou'?d\\b\", \"you would\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\byou'?ll\\b\", \"you will\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\byou'?re\\b\", \"you are\", tweet, flags=re.I)\n    tweet = re.sub(r\"\\byou'?ve\\b\", \"you have\", tweet, flags=re.I)\n\n    if tweet.find('woulded') != -1:\n        print('oe')\n\n    return tweet\n\ndef manage_url_tweet_characters(tweet):\n    tweet = tweet.text\n    tweet_ = tweet\n\n    tweet = re.sub(r\"https?:\\/\\/t.co\\/[A-Za-z0-9]+\", \"\", tweet)\n    tweet = re.sub('#', '', tweet)\n    tweet = re.sub('@.*', 'author', tweet)\n    tweet = re.sub('\\n', ' ', tweet)\n\n    tweet = re.sub('_', ' ', tweet)\n\n    # Character entity references\n    tweet = re.sub(r\"&gt;\", \" \", tweet)\n    tweet = re.sub(r\"&lt;\", \" \", tweet)\n    tweet = re.sub(r\"&amp;\", \" \", tweet)\n\n    # Extended Characters\n    tweet = tweet.encode('iso-8859-1').decode('ascii', 'ignore')\n\n    return tweet\n\n\ndef manage_tricks(tweet):\n    tweet = tweet.text\n    tweet_ = tweet\n\n    # Three letters\n    tweet = re.sub(r'([a-z])\\1\\1+', r'\\1\\1', tweet)\n    tweet = re.sub(r'([A-Z])\\1\\1+', r'\\1\\1', tweet)\n\n    # LetterNumber -> Letter -> Number\n    tweet = re.sub(\"([a-zA-Z])(\\d)\", r\"\\1 \\2\", tweet)\n    tweet = re.sub(\"(\\d)([a-zA-Z])\", r\"\\1 \\2\", tweet)\n\n    # HowAreYou -> How Are You\n    tweet = re.sub('([a-z])([A-Z])', r'\\1 \\2', tweet)\n\n    # numbers & percentage\n    re.sub(r'\\s[\\+~\\-]?\\d+[\\.,\\']?\\d*\\%', ' percentage ', tweet)\n    tweet = re.sub(r'\\s[\\+~\\-]?\\d+[\\.,\\']?\\d*\\s', ' number ', tweet)\n\n    # Dates and times\n    tweet = re.sub('\\d\\d:\\d\\d:\\d\\d', 'time', tweet)\n    tweet = re.sub('\\d\\d/\\d\\d/\\d\\d', 'date', tweet)\n    tweet = re.sub('\\d\\d/\\d\\d/\\d\\d\\d\\d', 'date', tweet)\n\n    # letter weird letter\n    tweet = re.sub('(\\d),(\\d)', r'\\1\\2', tweet)\n    tweet = re.sub(r'(\\d)\\.(\\d)', r'\\1\\2', tweet)\n    tweet = re.sub('([a-zA-Z0-9])[^a-zA-Z0-9]([a-zA-Z0-9])', r'\\1 \\2', tweet)\n\n    # dot letter\n    tweet = re.sub(r'\\b\\.([a-zA-Z])', r'\\1', tweet)\n\n    # remove more than two spaces\n    tweet = re.sub(r' +', r' ', tweet)\n\n    if tweet.find('Rescuers recover') != -1:\n        print('eo')\n\n    if tweet.find(r'\\.author') != -1:\n        print('eo')\n\n    return tweet\n\n\ndef manage_ner(tweet, nlp):\n    tweet = tweet.text\n    # PERSON    People, including    fictional.\n    # NORP    Nationalities or religious or political    groups.\n    # FAC    Buildings, airports, highways, bridges, etc.\n    # ORG    Companies, agencies, institutions, etc.\n    # GPE    Countries, cities, states.\n    # LOC     \tNon-GPE locations, mountain ranges, bodies of water.\n    # MONEY    Monetary    values, including    unit.\n    labels = ['PERSON', 'NORP', 'FAC', 'ORG', 'GPE', 'LOC', 'MONEY']\n    tweet_ = tweet\n    tweet = re.sub('[\\|\\(\\)]', '', tweet)\n    tweet = re.sub(\"'\", '', tweet)\n    doc = nlp(tweet)\n\n\n    for ent in doc.ents:\n        if ent.label_ in labels:\n            try:\n                if os.name == 'nt':\n                    tweet = re.sub('('+ent.text+')', ent.label_, tweet)\n                else:\n                    tweet = re.sub('('+ent.text+')', ent.label_+' \\\\1', tweet)\n            except:\n                pass\n\n    if tweet.find('ORGDemolition') != -1:\n        print('person')\n\n    if tweet.find('PERSONDetonate') != -1:\n        print('person')\n\n\n    return tweet\n\n\ndef manage_no_dictionable(tweet, nlp, spell):\n    id = tweet.id\n\n    tweet = tweet.text\n    doc = nlp(tweet)\n    for word in doc:\n        if word.has_vector:\n            pass\n        else:\n            if id % 100000000 == 0:\n                print(id)\n                print(str(word))\n            new_words = split_multi_word(str(word), spell, 4)\n            if id % 100000000 == 0:\n                print(new_words)\n            try:\n                tweet_ = tweet\n                tweet = re.sub(str(word), new_words, tweet)\n                manage_no_dictionable.dic[tweet_] = tweet\n            except:\n                pass\n    return tweet\n\n\ndef is_vectorable(word, spell):\n    if len(word) < 3:\n        return False\n    if spell.known([word]):\n        return word\n    else:\n        for i in range(3, len(word)):\n            w1 = word[0:i]\n            w2 = word[i:]\n\n            w1_r = is_vectorable(w1, spell)\n            w2_r = is_vectorable(w2, spell)\n\n            if w1_r and w2_r:\n                return w1_r + ' ' + w2_r\n\n        return False\n\n\ndef split_multi_word(word, spell, depth):\n    try:\n        aux = split_multi_word.dict[word]\n        return aux[0], aux[1]\n    except:\n        if word == '':\n            return '', 0\n        else:\n            if spell.known([word]):\n                return word, 1/len(word)\n            else:\n                if depth > 0:\n                    the_score = len(word)\n                    the_sub_words = word\n                    for l in range(min(12, len(word)), 0, -1):\n                        for i in range(0, len(word)-l+1):\n                            sub_word = word[i:i+l]\n                            if spell.known([sub_word]):\n                                score = 1/len(sub_word)\n\n                                word_left = word[0:i]\n                                word_right = word[i+l:]\n\n                                sub_words_left, score_left = split_multi_word(word_left, spell, depth - 1)\n                                sub_words_right, score_right = split_multi_word(word_right, spell, depth - 1)\n\n                                score = score_left + score + score_right\n                                sub_words = sub_words_left + ' ' + sub_word + ' ' + sub_words_right\n\n                                if the_score > score:\n                                    the_score = score\n                                    the_sub_words = sub_words\n                else:\n                    the_score = 1/len(word)\n                    the_sub_words = word\n                split_multi_word.dict[word] = [the_sub_words, the_score]\n                return the_sub_words, the_score\n\n\nsplit_multi_word.dict = {}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    print(\"Parsing texts...\")\n    print(\"url characters...\")\n    train_df['text_cleaned'] = train_df.apply(lambda tweet: manage_url_tweet_characters(tweet), axis=1)\n    test_df['text_cleaned'] = test_df.apply(lambda tweet: manage_url_tweet_characters(tweet), axis=1)\n    print('contractions')\n    train_df['text_cleaned'] = train_df.apply(lambda tweet: manage_contractions(tweet), axis=1)\n    test_df['text_cleaned'] = test_df.apply(lambda tweet: manage_contractions(tweet), axis=1)\n    print('manage_tricks')\n    train_df['text_cleaned'] = train_df.apply(lambda tweet: manage_tricks(tweet), axis=1)\n    test_df['text_cleaned'] = test_df.apply(lambda tweet: manage_tricks(tweet), axis=1)\n    print('ner')\n    train_df['text_cleaned'] = train_df.apply(lambda tweet: manage_ner(tweet, nlp_ents), axis=1)\n    test_df['text_cleaned'] = test_df.apply(lambda tweet: manage_ner(tweet, nlp_ents), axis=1)\n    print('multi_word')\n    train_df['text_cleaned'] = train_df.apply(lambda tweet: manage_no_dictionable(tweet, nlp_vects, spell), axis=1)\n    test_df['text_cleaned'] = test_df.apply(lambda tweet: manage_no_dictionable(tweet, nlp_vects, spell), axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **5. Mislabeled Samples**\nThere are **18** unique tweets in training set which are labeled differently in their duplicates. Those tweets are probably labeled by different people and they interpreted the meaning differently because some of them are not very clear. Tweets with two unique `target` values are relabeled since they can affect the training score."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mislabeled = df_train.groupby(['text']).nunique().sort_values(by='target', ascending=False)\ndf_mislabeled = df_mislabeled[df_mislabeled['target'] > 1]['target']\ndf_mislabeled.index.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['target_relabeled'] = df_train['target'].copy() \n\ndf_train.loc[df_train['text'] == 'like for the music video I want some real action shit like burning buildings and police chases not some weak ben winston shit', 'target_relabeled'] = 0\ndf_train.loc[df_train['text'] == 'Hellfire is surrounded by desires so be careful and donÛªt let your desires control you! #Afterlife', 'target_relabeled'] = 0\ndf_train.loc[df_train['text'] == 'To fight bioterrorism sir.', 'target_relabeled'] = 0\ndf_train.loc[df_train['text'] == '.POTUS #StrategicPatience is a strategy for #Genocide; refugees; IDP Internally displaced people; horror; etc. https://t.co/rqWuoy1fm4', 'target_relabeled'] = 1\ndf_train.loc[df_train['text'] == 'CLEARED:incident with injury:I-495  inner loop Exit 31 - MD 97/Georgia Ave Silver Spring', 'target_relabeled'] = 1\ndf_train.loc[df_train['text'] == '#foodscare #offers2go #NestleIndia slips into loss after #Magginoodle #ban unsafe and hazardous for #humanconsumption', 'target_relabeled'] = 0\ndf_train.loc[df_train['text'] == 'In #islam saving a person is equal in reward to saving all humans! Islam is the opposite of terrorism!', 'target_relabeled'] = 0\ndf_train.loc[df_train['text'] == 'Who is bringing the tornadoes and floods. Who is bringing the climate change. God is after America He is plaguing her\\n \\n#FARRAKHAN #QUOTE', 'target_relabeled'] = 1\ndf_train.loc[df_train['text'] == 'RT NotExplained: The only known image of infamous hijacker D.B. Cooper. http://t.co/JlzK2HdeTG', 'target_relabeled'] = 1\ndf_train.loc[df_train['text'] == \"Mmmmmm I'm burning.... I'm burning buildings I'm building.... Oooooohhhh oooh ooh...\", 'target_relabeled'] = 0\ndf_train.loc[df_train['text'] == \"wowo--=== 12000 Nigerian refugees repatriated from Cameroon\", 'target_relabeled'] = 0\ndf_train.loc[df_train['text'] == \"He came to a land which was engulfed in tribal war and turned it into a land of peace i.e. Madinah. #ProphetMuhammad #islam\", 'target_relabeled'] = 0\ndf_train.loc[df_train['text'] == \"Hellfire! We donÛªt even want to think about it or mention it so letÛªs not do anything that leads to it #islam!\", 'target_relabeled'] = 0\ndf_train.loc[df_train['text'] == \"The Prophet (peace be upon him) said 'Save yourself from Hellfire even if it is by giving half a date in charity.'\", 'target_relabeled'] = 0\ndf_train.loc[df_train['text'] == \"Caution: breathing may be hazardous to your health.\", 'target_relabeled'] = 1\ndf_train.loc[df_train['text'] == \"I Pledge Allegiance To The P.O.P.E. And The Burning Buildings of Epic City. ??????\", 'target_relabeled'] = 0\ndf_train.loc[df_train['text'] == \"#Allah describes piling up #wealth thinking it would last #forever as the description of the people of #Hellfire in Surah Humaza. #Reflect\", 'target_relabeled'] = 0\ndf_train.loc[df_train['text'] == \"that horrible sinking feeling when youÛªve been at home on your phone for a while and you realise its been on 3G this whole time\", 'target_relabeled'] = 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **6. Cross-validation**\nFirst of all, when the training/test sets are concatenated, and tweet counts by `keyword` are computed, it can be seen that training and test set are split inside `keyword` groups. We can also come to that conclusion by looking at `id` feature. This means every `keyword` are stratified while creating training and test set. We can replicate the same split for cross-validation.\n\nTweets from every `keyword` group exist in both training and test set and they are from the same sample. In order to replicate the same split technique, `StratifiedKFold` is used and `keyword` is passed as `y`, so stratification is done based on the `keyword` feature. `shuffle` is set to `True` for extra training diversity. Both folds have tweets from every `keyword` group in training and validation sets which can be seen from below."},{"metadata":{"trusted":true},"cell_type":"code","source":"K = 2\nskf = StratifiedKFold(n_splits=K, random_state=SEED, shuffle=True)\n\nDISASTER = df_train['target'] == 1\nprint('Whole Training Set Shape = {}'.format(df_train.shape))\nprint('Whole Training Set Unique keyword Count = {}'.format(df_train['keyword'].nunique()))\nprint('Whole Training Set Target Rate (Disaster) {}/{} (Not Disaster)'.format(df_train[DISASTER]['target_relabeled'].count(), df_train[~DISASTER]['target_relabeled'].count()))\n\nfor fold, (trn_idx, val_idx) in enumerate(skf.split(df_train['text_cleaned'], df_train['target']), 1):\n    print('\\nFold {} Training Set Shape = {} - Validation Set Shape = {}'.format(fold, df_train.loc[trn_idx, 'text_cleaned'].shape, df_train.loc[val_idx, 'text_cleaned'].shape))\n    print('Fold {} Training Set Unique keyword Count = {} - Validation Set Unique keyword Count = {}'.format(fold, df_train.loc[trn_idx, 'keyword'].nunique(), df_train.loc[val_idx, 'keyword'].nunique()))    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **7. Model**"},{"metadata":{},"cell_type":"markdown","source":"### **7.1 Metric**\nThe leaderboard is based on **Mean F-Score** which can be implemented with **Macro Average F1 Score**. However, it won't be very informative without **Accuracy**, **Precision** and **Recall** because classes are almost balanced and it is hard to tell which class is harder to predict.\n\n* **Accuracy** measures the fraction of the total sample that is correctly identified\n* **Precision** measures that out of all the examples predicted as positive, how many are actually positive\n* **Recall** measures that out of all the actual positives, how many examples were correctly classified as positive by the model\n* **F1 Score** is the harmonic mean of the **Precision** and **Recall**\n\nKeras has accuracy in its `metrics` module, but doesn't have rest of the metrics stated above. Another crucial point is **Precision**, **Recall** and **F1-Score** are global metrics so they should be calculated on whole training or validation set. Computing them on every batch would be both misleading and ineffective in terms of execution time. `ClassificationReport` which is similar to `sklearn.metrics.classification_report`, computes those metrics after every epoch for the given training and validation set."},{"metadata":{"trusted":true},"cell_type":"code","source":"class ClassificationReport(Callback):\n    \n    def __init__(self, train_data=(), validation_data=()):\n        super(Callback, self).__init__()\n        \n        self.X_train, self.y_train = train_data\n        self.train_precision_scores = []\n        self.train_recall_scores = []\n        self.train_f1_scores = []\n        \n        self.X_val, self.y_val = validation_data\n        self.val_precision_scores = []\n        self.val_recall_scores = []\n        self.val_f1_scores = [] \n               \n    def on_epoch_end(self, epoch, logs={}):\n        train_predictions = np.round(self.model.predict(self.X_train, verbose=0))        \n        train_precision = precision_score(self.y_train, train_predictions, average='macro')\n        train_recall = recall_score(self.y_train, train_predictions, average='macro')\n        train_f1 = f1_score(self.y_train, train_predictions, average='macro')\n        self.train_precision_scores.append(train_precision)        \n        self.train_recall_scores.append(train_recall)\n        self.train_f1_scores.append(train_f1)\n        \n        val_predictions = np.round(self.model.predict(self.X_val, verbose=0))\n        val_precision = precision_score(self.y_val, val_predictions, average='macro')\n        val_recall = recall_score(self.y_val, val_predictions, average='macro')\n        val_f1 = f1_score(self.y_val, val_predictions, average='macro')\n        self.val_precision_scores.append(val_precision)        \n        self.val_recall_scores.append(val_recall)        \n        self.val_f1_scores.append(val_f1)\n        \n        print('\\nEpoch: {} - Training Precision: {:.6} - Training Recall: {:.6} - Training F1: {:.6}'.format(epoch + 1, train_precision, train_recall, train_f1))\n        print('Epoch: {} - Validation Precision: {:.6} - Validation Recall: {:.6} - Validation F1: {:.6}'.format(epoch + 1, val_precision, val_recall, val_f1))  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **7.2 BERT Layer**\n\nThis model uses the implementation of BERT from the TensorFlow Models repository on GitHub at `tensorflow/models/official/nlp/bert`. It uses L=12 hidden layers (Transformer blocks), a hidden size of H=768, and A=12 attention heads.\n\nThis model has been pre-trained for English on the Wikipedia and BooksCorpus. Inputs have been **\"uncased\"**, meaning that the text has been lower-cased before tokenization into word pieces, and any accent markers have been stripped. In order to download this model, `Internet` must be activated on the kernel."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nbert_layer = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1', trainable=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **7.3 Architecture**\n`DisasterDetector` is a wrapper that incorporates the cross-validation and metrics stated above. \n\nThe tokenization of input text is performed with the `FullTokenizer` class from `tensorflow/models/official/nlp/bert/tokenization.py`. `max_seq_length` parameter can be used for tuning the sequence length of text.\n\nParameters such as `lr`, `epochs` and `batch_size` can be used for controlling the learning process. There are no dense or pooling layers added after last layer of BERT. `SGD` is used as optimizer since others have hard time while converging.\n\n`plot_learning_curve` plots **Accuracy**, **Precision**, **Recall** and **F1 Score** (for validation set) stored after every epoch alongside with training/validation loss curve. This helps to see which metric fluctuates most while training."},{"metadata":{"trusted":true},"cell_type":"code","source":"class DisasterDetector:\n    \n    def __init__(self, bert_layer, max_seq_length=128, lr=0.0001, epochs=15, batch_size=32):\n        \n        # BERT and Tokenization params\n        self.bert_layer = bert_layer\n        \n        self.max_seq_length = max_seq_length        \n        vocab_file = self.bert_layer.resolved_object.vocab_file.asset_path.numpy()\n        do_lower_case = self.bert_layer.resolved_object.do_lower_case.numpy()\n        self.tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n        \n        # Learning control params\n        self.lr = lr\n        self.epochs = epochs\n        self.batch_size = batch_size\n        \n        self.models = []\n        self.scores = {}\n        \n        \n    def encode(self, texts):\n                \n        all_tokens = []\n        all_masks = []\n        all_segments = []\n\n        for text in texts:\n            text = self.tokenizer.tokenize(text)\n            text = text[:self.max_seq_length - 2]\n            input_sequence = ['[CLS]'] + text + ['[SEP]']\n            pad_len = self.max_seq_length - len(input_sequence)\n\n            tokens = self.tokenizer.convert_tokens_to_ids(input_sequence)\n            tokens += [0] * pad_len\n            pad_masks = [1] * len(input_sequence) + [0] * pad_len\n            segment_ids = [0] * self.max_seq_length\n\n            all_tokens.append(tokens)\n            all_masks.append(pad_masks)\n            all_segments.append(segment_ids)\n\n        return np.array(all_tokens), np.array(all_masks), np.array(all_segments)\n    \n    \n    def build_model(self):\n        \n        input_word_ids = Input(shape=(self.max_seq_length,), dtype=tf.int32, name='input_word_ids')\n        input_mask = Input(shape=(self.max_seq_length,), dtype=tf.int32, name='input_mask')\n        segment_ids = Input(shape=(self.max_seq_length,), dtype=tf.int32, name='segment_ids')    \n        \n        pooled_output, sequence_output = self.bert_layer([input_word_ids, input_mask, segment_ids])   \n        clf_output = sequence_output[:, 0, :]\n        out = Dense(1, activation='sigmoid')(clf_output)\n        \n        model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n        optimizer = SGD(learning_rate=self.lr, momentum=0.8)\n        model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n        \n        return model\n    \n    \n    def train(self, X):\n        \n        for fold, (trn_idx, val_idx) in enumerate(skf.split(X['text_cleaned'], X['keyword'])):\n            \n            print('\\nFold {}\\n'.format(fold))\n        \n            X_trn_encoded = self.encode(X.loc[trn_idx, 'text_cleaned'].str.lower())\n            y_trn = X.loc[trn_idx, 'target_relabeled']\n            X_val_encoded = self.encode(X.loc[val_idx, 'text_cleaned'].str.lower())\n            y_val = X.loc[val_idx, 'target_relabeled']\n        \n            # Callbacks\n            metrics = ClassificationReport(train_data=(X_trn_encoded, y_trn), validation_data=(X_val_encoded, y_val))\n            \n            # Model\n            model = self.build_model()        \n            model.fit(X_trn_encoded, y_trn, validation_data=(X_val_encoded, y_val), callbacks=[metrics], epochs=self.epochs, batch_size=self.batch_size)\n            \n            self.models.append(model)\n            self.scores[fold] = {\n                'train': {\n                    'precision': metrics.train_precision_scores,\n                    'recall': metrics.train_recall_scores,\n                    'f1': metrics.train_f1_scores                    \n                },\n                'validation': {\n                    'precision': metrics.val_precision_scores,\n                    'recall': metrics.val_recall_scores,\n                    'f1': metrics.val_f1_scores                    \n                }\n            }\n                    \n                \n    def plot_learning_curve(self):\n        \n        fig, axes = plt.subplots(nrows=K, ncols=2, figsize=(20, K * 6), dpi=100)\n    \n        for i in range(K):\n            \n            # Classification Report curve\n            sns.lineplot(x=np.arange(1, self.epochs + 1), y=clf.models[i].history.history['val_accuracy'], ax=axes[i][0], label='val_accuracy')\n            sns.lineplot(x=np.arange(1, self.epochs + 1), y=clf.scores[i]['validation']['precision'], ax=axes[i][0], label='val_precision')\n            sns.lineplot(x=np.arange(1, self.epochs + 1), y=clf.scores[i]['validation']['recall'], ax=axes[i][0], label='val_recall')\n            sns.lineplot(x=np.arange(1, self.epochs + 1), y=clf.scores[i]['validation']['f1'], ax=axes[i][0], label='val_f1')        \n\n            axes[i][0].legend() \n            axes[i][0].set_title('Fold {} Validation Classification Report'.format(i), fontsize=14)\n\n            # Loss curve\n            sns.lineplot(x=np.arange(1, self.epochs + 1), y=clf.models[0].history.history['loss'], ax=axes[i][1], label='train_loss')\n            sns.lineplot(x=np.arange(1, self.epochs + 1), y=clf.models[0].history.history['val_loss'], ax=axes[i][1], label='val_loss')\n\n            axes[i][1].legend() \n            axes[i][1].set_title('Fold {} Train / Validation Loss'.format(i), fontsize=14)\n\n            for j in range(2):\n                axes[i][j].set_xlabel('Epoch', size=12)\n                axes[i][j].tick_params(axis='x', labelsize=12)\n                axes[i][j].tick_params(axis='y', labelsize=12)\n\n        plt.show()\n        \n        \n    def predict(self, X):\n        \n        X_test_encoded = self.encode(X['text_cleaned'].str.lower())\n        y_pred = np.zeros((X_test_encoded[0].shape[0], 1))\n\n        for model in self.models:\n            y_pred += model.predict(X_test_encoded) / len(self.models)\n\n        return y_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **7.4 Training, Evaluation and Prediction**"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = DisasterDetector(bert_layer, max_seq_length=128, lr=0.0001, epochs=10, batch_size=32)\n\nclf.train(df_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"clf.plot_learning_curve()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = clf.predict(df_test)\n\nmodel_submission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")\nmodel_submission['target'] = np.round(y_pred).astype('int')\nmodel_submission.to_csv('model_submission.csv', index=False)\nmodel_submission.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **8. Test Set Labels**\nTest set labels can be found on [this](https://www.figure-eight.com/data-for-everyone/) website. Dataset is named **Disasters on social media**. This is how people are submitting perfect scores. Other \"Getting Started\" competitions also have their test labels available. The main point of \"Getting Started\" competitions is **learning and sharing**, and perfect score doesn't mean anything. \n\n> **Phil Culliton wrote:**\n> For the AutoML prize, any use of the label set will result in disqualification.\n\nAccording to [@philculliton](https://www.kaggle.com/philculliton) from Kaggle Team, competitors who use test set labels in any way are not eligible to win AutoML prize. There are no other penalties for using them."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_leak = pd.read_csv('../input/nlp-with-disaster-tweets-test-set-with-labels/socialmedia-disaster-tweets-DFE.csv', encoding ='ISO-8859-1')[['choose_one', 'text']]\n\n# Creating target and id\ndf_leak['target'] = (df_leak['choose_one'] == 'Relevant').astype(np.int8)\ndf_leak['id'] = df_leak.index.astype(np.int16)\ndf_leak.drop(columns=['choose_one', 'text'], inplace=True)\n\n# Merging target to test set\ndf_test = df_test.merge(df_leak, on=['id'], how='left')\n\nprint('Leaked Data Set Shape = {}'.format(df_leak.shape))\nprint('Leaked Data Set Memory Usage = {:.2f} MB'.format(df_leak.memory_usage().sum() / 1024**2))\n\nperfect_submission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")\nperfect_submission['target'] = df_test['target'].values\nperfect_submission.to_csv('perfect_submission.csv', index=False)\nperfect_submission.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **9. Preprocessed Datasets**\nPreprocessed datasets are saved in pickle format for people who don't want to wait for preprocessing. Instead of forking and waiting for all preprocessing operations, it is easier to use this kernel as a data source in your own kernel. It can be done by searching and selecting this kernel after clicking `+ Add Data` button."},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_FEATURES = ['id', 'keyword', 'location', 'text', 'target', 'text_cleaned', 'target_relabeled']\nTEST_FEATURES = ['id', 'keyword', 'location', 'text', 'target', 'text_cleaned']\n\ndf_train[TRAIN_FEATURES].to_pickle('train.pkl')\ndf_test[TEST_FEATURES].to_pickle('test.pkl')\n\nprint('Training Set Shape = {}'.format(df_train[TRAIN_FEATURES].shape))\nprint('Training Set Memory Usage = {:.2f} MB'.format(df_train[TRAIN_FEATURES].memory_usage().sum() / 1024**2))\nprint('Test Set Shape = {}'.format(df_test[TEST_FEATURES].shape))\nprint('Test Set Memory Usage = {:.2f} MB'.format(df_test[TEST_FEATURES].memory_usage().sum() / 1024**2))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}